{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2017741046_임준오_Assignment_11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plyATQM4MVu8"
      },
      "source": [
        "##**3 Assignment**\n",
        "\n",
        "###**다음 미완성 코드를 활용해 새로운 data를 학습해보자**\n",
        "\n",
        "* Training data image\n",
        "  * Shape: (?, 3, 64, 128)\n",
        "    * 여러장의, RGB, 64x128 size의 이미지라고 가정하자\n",
        "\n",
        "* Test data image\n",
        "  * Shape: (?, 3, ?, ?)\n",
        "    * 여러장의, RGB, size를 알 수 없는 이미지라고 가정하자\n",
        "\n",
        "* Labels\n",
        "  * image의 class는 2가지 이다\n",
        "  * data folder의 구성을 참고하자\n",
        "\n",
        "* Data folder 위치\n",
        "  * 노트북 github의 data folder 2개를 적당한 위치에 카피해 사용한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvVjhzH6e0uZ",
        "outputId": "f1281637-34c5-4d4c-e0f9-b51ce5e33e32"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.datasets as dsets\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as opt\n",
        "from torch.utils.data import DataLoader\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "tf = transforms.Compose([transforms.Resize((64,128)), transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\n",
        "\n",
        "trainset = dsets.ImageFolder(root = '/content/drive/MyDrive/origin_data',transform=tf)\n",
        "testset = dsets.ImageFolder(root = '/content/drive/MyDrive/test_data',transform=tf)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=16, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=16, shuffle=True)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN,self).__init__()\n",
        "        self.layer1 = nn.Sequential(nn.Conv2d(3, 32, 3, padding=1),\n",
        "                      nn.ReLU(), nn.MaxPool2d(2, stride=2))\n",
        "        self.layer2 = nn.Sequential(nn.Conv2d(32, 64, 3, padding=1),\n",
        "                      nn.ReLU(), nn.MaxPool2d(2, stride=2))\n",
        "        self.layer3 = nn.Sequential(nn.Conv2d(64, 128, 3, padding=1),\n",
        "                      nn.ReLU(), nn.MaxPool2d(2, stride=2, padding=1))\n",
        "        self.layer4 = nn.Sequential(nn.Linear(19584, 5000),\n",
        "                      nn.ReLU(), nn.Dropout()) \n",
        "        self.linear1 = nn.Linear(5000, 500)\n",
        "        self.linear2 = nn.Linear(500, 2) \n",
        "\n",
        "    def forward(self,x):\n",
        "        in_size = x.size(0)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = x.reshape(in_size, -1)\n",
        "        x = self.layer4(x)\n",
        "        x = self.linear1(x)\n",
        "        x = self.linear2(x) \n",
        "        return x\n",
        "\n",
        "learning_rate = 0.005\n",
        "training_epochs = 10\n",
        "\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = opt.Adam(model.parameters(),lr=learning_rate)\n",
        "\n",
        "total_batch = len(trainloader)\n",
        "for epoch in range(training_epochs):\n",
        "    total_loss = 0\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs,labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs)\n",
        "        loss = criterion(output,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss / total_batch\n",
        "\n",
        "    print('[Epoch: {:>4}] loss = {:>.9}'.format(epoch + 1, avg_loss))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for test_inputs, test_labels in testloader:\n",
        "        test_inputs,test_labels = test_inputs.to(device), test_labels.to(device)\n",
        "        test_output = model(test_inputs)\n",
        "        correct_prediction = torch.argmax(test_output, 1) == test_labels\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item() * 100,'%')\n",
        "\n",
        "#주어진 학습데이터에 대해 모델의 깊이가 깊어 완벽하게 학습되었다. "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch:    1] loss = 0.0\n",
            "[Epoch:    2] loss = 0.0\n",
            "[Epoch:    3] loss = 0.0\n",
            "[Epoch:    4] loss = 0.0\n",
            "[Epoch:    5] loss = 0.0\n",
            "[Epoch:    6] loss = 0.0\n",
            "[Epoch:    7] loss = 0.0\n",
            "[Epoch:    8] loss = 0.0\n",
            "[Epoch:    9] loss = 0.0\n",
            "[Epoch:   10] loss = 0.0\n",
            "Accuracy: 100.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_hXAsMPvTKw",
        "outputId": "72c06afc-1701-4989-af25-1814ec736653"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.datasets as dsets\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as opt\n",
        "from torch.utils.data import DataLoader\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "tf = transforms.Compose([transforms.Resize((64,128)), transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\n",
        "\n",
        "trainset = dsets.ImageFolder(root = '/content/drive/MyDrive/origin_data',transform=tf)\n",
        "testset = dsets.ImageFolder(root = '/content/drive/MyDrive/test_data',transform=tf)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=16, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=16, shuffle=True)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN,self).__init__()\n",
        "        self.layer1 = nn.Sequential(nn.Conv2d(3, 32, 3, padding=1),\n",
        "                      nn.ReLU(), nn.MaxPool2d(2, stride=2))\n",
        "        self.layer2 = nn.Sequential(nn.Conv2d(32, 64, 3, padding=1),\n",
        "                      nn.ReLU(), nn.MaxPool2d(2, stride=2))\n",
        "        self.layer3 = nn.Sequential(nn.Conv2d(64, 128, 3, padding=1),\n",
        "                      nn.ReLU(), nn.MaxPool2d(2, stride=2, padding=1))\n",
        "        self.layer4 = nn.Sequential(nn.Linear(19584, 5000),\n",
        "                      nn.ReLU(), nn.Dropout()) \n",
        "        self.linear1 = nn.Linear(5000, 500)\n",
        "        self.linear2 = nn.Linear(500, 2) \n",
        "\n",
        "    def forward(self,x):\n",
        "        in_size = x.size(0)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = x.reshape(in_size, -1)\n",
        "        x = self.layer4(x)\n",
        "        x = self.linear1(x)\n",
        "        x = self.linear2(x) \n",
        "        return x\n",
        "\n",
        "learning_rate = 0.005\n",
        "training_epochs = 10\n",
        "\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = opt.Adam(model.parameters(),lr=learning_rate)\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    loss_sum = 0\n",
        "    correct1 = 0\n",
        "    total1 = 0\n",
        "    for i, data in enumerate(trainloader,0):\n",
        "        inputs,labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs)\n",
        "        loss = criterion(output,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, pred = torch.max(output.data, 1)\n",
        "        total1 += labels.size(0)\n",
        "        correct1 += (pred==labels).sum().item()\n",
        "        loss_sum += loss.item()\n",
        "        if i % 2000 == 1999:    \n",
        "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, loss_sum / 2000))\n",
        "            loss_sum = 0.0\n",
        "            \n",
        "    print('epoch %d Accuracy: %d %%' %(epoch+1, 100*correct1/total1))\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device),data[1].to(device)\n",
        "        output = model(images)\n",
        "        _, pred1 = torch.max(output.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (pred1 == labels).sum().item()\n",
        "\n",
        "print('Accuracy of test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 Accuracy: 83 %\n",
            "epoch 2 Accuracy: 100 %\n",
            "epoch 3 Accuracy: 97 %\n",
            "epoch 4 Accuracy: 100 %\n",
            "epoch 5 Accuracy: 100 %\n",
            "epoch 6 Accuracy: 100 %\n",
            "epoch 7 Accuracy: 100 %\n",
            "epoch 8 Accuracy: 100 %\n",
            "epoch 9 Accuracy: 100 %\n",
            "epoch 10 Accuracy: 100 %\n",
            "Accuracy of test images: 100 %\n"
          ]
        }
      ]
    }
  ]
}